#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Ù†Ø¸Ø§Ù… ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ÙÙ‡Ø§Ø±Ø³ Ø§Ù„Ø´Ø§Ù…Ù„ ÙˆØ§Ù„Ù…ØªÙƒØ§Ù…Ù„
ULTIMATE DATABASE INDEXING APPLICATION SYSTEM

Ù‡Ø°Ø§ Ø§Ù„Ø³ÙƒØ±ÙŠØ¨Øª ÙŠØ·Ø¨Ù‚ Ø¬Ù…ÙŠØ¹ Ø§Ù„ÙÙ‡Ø§Ø±Ø³ Ø§Ù„Ù…Ø­Ø³Ù†Ø© Ø¹Ù„Ù‰ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
Ù…Ø¹ Ø¥Ù…ÙƒØ§Ù†ÙŠØ© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø¹Ù„Ù‰ Ø®Ø§Ø¯Ù… Ø«Ø§Ù†ÙˆÙŠ Ø£Ùˆ Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù†ÙØµÙ„Ø©
"""

import argparse
import json
import logging
import os
import sys
import time
from datetime import datetime
from typing import Dict, List, Optional, Tuple

import psycopg2

# Ø¥Ø¹Ø¯Ø§Ø¯ Ù†Ø¸Ø§Ù… Ø§Ù„Ø³Ø¬Ù„Ø§Øª
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[
        logging.FileHandler("ultimate_indexes_application.log", encoding="utf-8"),
        logging.StreamHandler(sys.stdout),
    ],
)
logger = logging.getLogger(__name__)


class UltimateIndexManager:
    """Ù…Ø¯ÙŠØ± Ø§Ù„ÙÙ‡Ø§Ø±Ø³ Ø§Ù„Ø´Ø§Ù…Ù„ ÙˆØ§Ù„Ù…ØªÙƒØ§Ù…Ù„"""

    def __init__(self, db_config: Dict[str, str]):
        """
        ØªÙ‡ÙŠØ¦Ø© Ù…Ø¯ÙŠØ± Ø§Ù„ÙÙ‡Ø§Ø±Ø³

        Args:
            db_config: Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        """
        self.db_config = db_config
        self.connection = None
        self.cursor = None
        self.stats = {
            "total_indexes": 0,
            "successful_indexes": 0,
            "failed_indexes": 0,
            "skipped_indexes": 0,
            "start_time": None,
            "end_time": None,
            "errors": [],
        }

    def connect_to_database(self) -> bool:
        """Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        try:
            logger.info("ğŸ”Œ Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...")
            self.connection = psycopg2.connect(
                host=self.db_config["host"],
                port=self.db_config["port"],
                database=self.db_config["database"],
                user=self.db_config["user"],
                password=self.db_config["password"],
            )
            self.cursor = self.connection.cursor()

            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø§ØªØµØ§Ù„
            self.cursor.execute("SELECT version();")
            version = self.cursor.fetchone()[0]
            logger.info(f"âœ… ØªÙ… Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù†Ø¬Ø§Ø­: {version}")

            return True

        except Exception as e:
            logger.error(f"âŒ ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {str(e)}")
            return False

    def disconnect_from_database(self):
        """Ù‚Ø·Ø¹ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        try:
            if self.cursor:
                self.cursor.close()
            if self.connection:
                self.connection.close()
            logger.info("ğŸ”Œ ØªÙ… Ù‚Ø·Ø¹ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù‚Ø·Ø¹ Ø§Ù„Ø§ØªØµØ§Ù„: {str(e)}")

    def check_existing_indexes(self) -> Dict[str, bool]:
        """ÙØ­Øµ Ø§Ù„ÙÙ‡Ø§Ø±Ø³ Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©"""
        try:
            logger.info("ğŸ” Ø¬Ø§Ø±ÙŠ ÙØ­Øµ Ø§Ù„ÙÙ‡Ø§Ø±Ø³ Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©...")

            query = """
            SELECT indexname 
            FROM pg_indexes 
            WHERE schemaname = 'public' 
            AND indexname LIKE 'idx_%'
            """

            self.cursor.execute(query)
            existing_indexes = {row[0]: True for row in self.cursor.fetchall()}

            logger.info(f"ğŸ“Š ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(existing_indexes)} ÙÙ‡Ø±Ø³ Ù…ÙˆØ¬ÙˆØ¯")
            return existing_indexes

        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ÙØ­Øµ Ø§Ù„ÙÙ‡Ø§Ø±Ø³ Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©: {str(e)}")
            return {}

    def parse_sql_file(self, file_path: str) -> List[str]:
        """ØªØ­Ù„ÙŠÙ„ Ù…Ù„Ù SQL ÙˆØ§Ø³ØªØ®Ø±Ø§Ø¬ Ø£ÙˆØ§Ù…Ø± Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ÙÙ‡Ø§Ø±Ø³"""
        try:
            logger.info(f"ğŸ“– Ø¬Ø§Ø±ÙŠ Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù Ø§Ù„ÙÙ‡Ø§Ø±Ø³: {file_path}")

            with open(file_path, "r", encoding="utf-8") as file:
                content = file.read()

            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£ÙˆØ§Ù…Ø± CREATE INDEX
            statements = []
            lines = content.split("\n")
            current_statement = ""

            for line in lines:
                line = line.strip()

                # ØªØ¬Ø§Ù‡Ù„ Ø§Ù„ØªØ¹Ù„ÙŠÙ‚Ø§Øª ÙˆØ§Ù„Ø£Ø³Ø·Ø± Ø§Ù„ÙØ§Ø±ØºØ©
                if not line or line.startswith("--") or line.startswith("/*"):
                    continue

                # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø³Ø·Ø± Ù„Ù„Ø£Ù…Ø± Ø§Ù„Ø­Ø§Ù„ÙŠ
                current_statement += line + " "

                # Ø¥Ø°Ø§ Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„Ø£Ù…Ø± Ø¨ÙØ§ØµÙ„Ø© Ù…Ù†Ù‚ÙˆØ·Ø©
                if line.endswith(";"):
                    statement = current_statement.strip()
                    if statement.upper().startswith("CREATE INDEX"):
                        statements.append(statement)
                    elif statement.upper().startswith("ANALYZE"):
                        statements.append(statement)
                    current_statement = ""

            logger.info(f"ğŸ“Š ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ {len(statements)} Ø£Ù…Ø± Ù…Ù† Ø§Ù„Ù…Ù„Ù")
            return statements

        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù SQL: {str(e)}")
            return []

    def extract_index_name(self, statement: str) -> Optional[str]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø³Ù… Ø§Ù„ÙÙ‡Ø±Ø³ Ù…Ù† Ø£Ù…Ø± CREATE INDEX"""
        try:
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ø³Ù… Ø§Ù„ÙÙ‡Ø±Ø³ ÙÙŠ Ø§Ù„Ø£Ù…Ø±
            parts = statement.split()
            for i, part in enumerate(parts):
                if part.upper() == "EXISTS":
                    if i + 1 < len(parts):
                        return parts[i + 1]
                elif part.upper() == "INDEX" and i + 1 < len(parts):
                    next_part = parts[i + 1]
                    if next_part.upper() not in ["CONCURRENTLY", "IF"]:
                        return next_part
            return None
        except Exception:
            return None

    def apply_index(
        self, statement: str, existing_indexes: Dict[str, bool]
    ) -> Tuple[bool, str]:
        """ØªØ·Ø¨ÙŠÙ‚ ÙÙ‡Ø±Ø³ ÙˆØ§Ø­Ø¯"""
        try:
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø³Ù… Ø§Ù„ÙÙ‡Ø±Ø³
            index_name = self.extract_index_name(statement)

            if not index_name:
                return False, "Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø³Ù… Ø§Ù„ÙÙ‡Ø±Ø³"

            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„ÙÙ‡Ø±Ø³
            if index_name in existing_indexes:
                logger.info(f"â­ï¸  Ø§Ù„ÙÙ‡Ø±Ø³ Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ù„ÙØ¹Ù„: {index_name}")
                self.stats["skipped_indexes"] += 1
                return True, "Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ù„ÙØ¹Ù„"

            # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ÙÙ‡Ø±Ø³
            logger.info(f"ğŸ”¨ Ø¬Ø§Ø±ÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ÙÙ‡Ø±Ø³: {index_name}")
            start_time = time.time()

            # ØªØ¹ÙŠÙŠÙ† autocommit Ù„Ù„ÙÙ‡Ø§Ø±Ø³ CONCURRENTLY
            if "CONCURRENTLY" in statement.upper():
                old_autocommit = self.connection.autocommit
                self.connection.autocommit = True
                try:
                    self.cursor.execute(statement)
                    self.connection.autocommit = old_autocommit
                except Exception as e:
                    self.connection.autocommit = old_autocommit
                    raise e
            else:
                self.cursor.execute(statement)
                self.connection.commit()

            end_time = time.time()
            duration = end_time - start_time

            logger.info(
                f"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ÙÙ‡Ø±Ø³ Ø¨Ù†Ø¬Ø§Ø­: {index_name} ({duration:.2f} Ø«Ø§Ù†ÙŠØ©)"
            )
            self.stats["successful_indexes"] += 1

            return True, f"ØªÙ… Ø§Ù„Ø¥Ù†Ø´Ø§Ø¡ ÙÙŠ {duration:.2f} Ø«Ø§Ù†ÙŠØ©"

        except Exception as e:
            error_msg = str(e)
            logger.error(f"âŒ ÙØ´Ù„ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ÙÙ‡Ø±Ø³: {error_msg}")
            self.stats["failed_indexes"] += 1
            self.stats["errors"].append(
                {
                    "statement": (
                        statement[:100] + "..." if len(statement) > 100 else statement
                    ),
                    "error": error_msg,
                    "timestamp": datetime.now().isoformat(),
                }
            )

            # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„ØªØ±Ø§Ø¬Ø¹ Ø¹Ù† Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª (ÙÙ‚Ø· Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† CONCURRENTLY)
            if "CONCURRENTLY" not in statement.upper():
                try:
                    self.connection.rollback()
                except Exception:
                    pass

            return False, error_msg

    def apply_all_indexes(self, sql_file_path: str) -> bool:
        """ØªØ·Ø¨ÙŠÙ‚ Ø¬Ù…ÙŠØ¹ Ø§Ù„ÙÙ‡Ø§Ø±Ø³ Ù…Ù† Ø§Ù„Ù…Ù„Ù"""
        try:
            logger.info("ğŸš€ Ø¨Ø¯Ø¡ ØªØ·Ø¨ÙŠÙ‚ Ù†Ø¸Ø§Ù… Ø§Ù„ÙÙ‡Ø±Ø³Ø© Ø§Ù„Ø´Ø§Ù…Ù„...")
            self.stats["start_time"] = datetime.now()

            # Ù‚Ø±Ø§Ø¡Ø© Ø£ÙˆØ§Ù…Ø± SQL
            statements = self.parse_sql_file(sql_file_path)
            if not statements:
                logger.error("âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£ÙˆØ§Ù…Ø± ØµØ§Ù„Ø­Ø© ÙÙŠ Ø§Ù„Ù…Ù„Ù")
                return False

            self.stats["total_indexes"] = len(statements)

            # ÙØ­Øµ Ø§Ù„ÙÙ‡Ø§Ø±Ø³ Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©
            existing_indexes = self.check_existing_indexes()

            # ØªØ·Ø¨ÙŠÙ‚ ÙƒÙ„ ÙÙ‡Ø±Ø³
            logger.info(f"ğŸ”¨ Ø¬Ø§Ø±ÙŠ ØªØ·Ø¨ÙŠÙ‚ {len(statements)} Ø£Ù…Ø±...")

            for i, statement in enumerate(statements, 1):
                logger.info(f"ğŸ“Š Ø§Ù„ØªÙ‚Ø¯Ù…: {i}/{len(statements)}")

                if statement.upper().startswith("ANALYZE"):
                    # ØªØ·Ø¨ÙŠÙ‚ Ø£Ù…Ø± ANALYZE
                    try:
                        self.cursor.execute(statement)
                        self.connection.commit()
                        logger.info(f"âœ… ØªÙ… ØªÙ†ÙÙŠØ° ANALYZE Ø¨Ù†Ø¬Ø§Ø­")
                    except Exception as e:
                        logger.warning(f"âš ï¸  ØªØ­Ø°ÙŠØ± ÙÙŠ ANALYZE: {str(e)}")
                else:
                    # ØªØ·Ø¨ÙŠÙ‚ ÙÙ‡Ø±Ø³
                    success, message = self.apply_index(statement, existing_indexes)
                    if not success and "Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ù„ÙØ¹Ù„" not in message:
                        logger.warning(f"âš ï¸  ØªØ­Ø°ÙŠØ±: {message}")

            self.stats["end_time"] = datetime.now()
            duration = (
                self.stats["end_time"] - self.stats["start_time"]
            ).total_seconds()

            # Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
            logger.info("=" * 60)
            logger.info("ğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ÙÙ‡Ø§Ø±Ø³:")
            logger.info(f"ğŸ“ˆ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø£ÙˆØ§Ù…Ø±: {self.stats['total_indexes']}")
            logger.info(f"âœ… Ù†Ø¬Ø­: {self.stats['successful_indexes']}")
            logger.info(f"â­ï¸  ØªÙ… ØªØ®Ø·ÙŠÙ‡: {self.stats['skipped_indexes']}")
            logger.info(f"âŒ ÙØ´Ù„: {self.stats['failed_indexes']}")
            logger.info(f"â±ï¸  Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ: {duration:.2f} Ø«Ø§Ù†ÙŠØ©")
            logger.info("=" * 60)

            if self.stats["failed_indexes"] > 0:
                logger.warning(f"âš ï¸  ØªØ­Ø°ÙŠØ±: ÙØ´Ù„ {self.stats['failed_indexes']} ÙÙ‡Ø±Ø³")
                return False

            logger.info("ğŸ‰ ØªÙ… ØªØ·Ø¨ÙŠÙ‚ Ù†Ø¸Ø§Ù… Ø§Ù„ÙÙ‡Ø±Ø³Ø© Ø¨Ù†Ø¬Ø§Ø­!")
            return True

        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ Ø¹Ø§Ù… ÙÙŠ ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ÙÙ‡Ø§Ø±Ø³: {str(e)}")
            return False

    def generate_report(self, output_file: str = "indexing_report.json"):
        """Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± Ù…ÙØµÙ„ Ø¹Ù† Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚"""
        try:
            # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØªÙˆØ§Ø±ÙŠØ® Ø¥Ù„Ù‰ Ù†ØµÙˆØµ
            stats_copy = self.stats.copy()
            if stats_copy.get("start_time"):
                stats_copy["start_time"] = stats_copy["start_time"].isoformat()
            if stats_copy.get("end_time"):
                stats_copy["end_time"] = stats_copy["end_time"].isoformat()

            report = {
                "timestamp": datetime.now().isoformat(),
                "database_config": {
                    "host": self.db_config["host"],
                    "port": self.db_config["port"],
                    "database": self.db_config["database"],
                    "user": self.db_config["user"],
                },
                "statistics": stats_copy,
                "success_rate": (
                    self.stats["successful_indexes"]
                    / max(self.stats["total_indexes"], 1)
                )
                * 100,
            }

            with open(output_file, "w", encoding="utf-8") as f:
                json.dump(report, f, ensure_ascii=False, indent=2)

            logger.info(f"ğŸ“„ ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ±: {output_file}")

        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ±: {str(e)}")


def load_database_config(config_file: str = None) -> Dict[str, str]:
    """ØªØ­Ù…ÙŠÙ„ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""

    # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ù„Ù„Ø®Ø§Ø¯Ù… Ø§Ù„Ù…Ø­Ù„ÙŠ
    default_config = {
        "host": "localhost",
        "port": "5432",
        "database": "crm_system",
        "user": "postgres",
        "password": "your_password",
    }

    # Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ­Ù…ÙŠÙ„ Ù…Ù† Ù…Ù„Ù Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
    if config_file and os.path.exists(config_file):
        try:
            with open(config_file, "r", encoding="utf-8") as f:
                config = json.load(f)
            logger.info(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù…Ù†: {config_file}")
            return config
        except Exception as e:
            logger.warning(f"âš ï¸  Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª: {str(e)}")

    # Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ­Ù…ÙŠÙ„ Ù…Ù† Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø©
    env_config = {}
    for key in default_config.keys():
        env_key = f"DB_{key.upper()}"
        if env_key in os.environ:
            env_config[key] = os.environ[env_key]

    if env_config:
        default_config.update(env_config)
        logger.info("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù…Ù† Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø©")

    return default_config


def main():
    """Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"""
    parser = argparse.ArgumentParser(
        description="Ù†Ø¸Ø§Ù… ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ÙÙ‡Ø§Ø±Ø³ Ø§Ù„Ø´Ø§Ù…Ù„ ÙˆØ§Ù„Ù…ØªÙƒØ§Ù…Ù„",
        formatter_class=argparse.RawDescriptionHelpFormatter,
    )

    parser.add_argument(
        "--sql-file",
        default="ULTIMATE_DATABASE_INDEXES.sql",
        help="Ù…Ø³Ø§Ø± Ù…Ù„Ù Ø§Ù„ÙÙ‡Ø§Ø±Ø³ SQL (Ø§ÙØªØ±Ø§Ø¶ÙŠ: ULTIMATE_DATABASE_INDEXES.sql)",
    )

    parser.add_argument(
        "--simple",
        action="store_true",
        help="Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ÙÙ‡Ø§Ø±Ø³ Ø§Ù„Ù…Ø¨Ø³Ø·Ø© Ø¨Ø¯ÙˆÙ† CONCURRENTLY (ULTIMATE_DATABASE_INDEXES_SIMPLE.sql)",
    )

    parser.add_argument("--config-file", help="Ù…Ø³Ø§Ø± Ù…Ù„Ù Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (JSON)")

    parser.add_argument("--host", help="Ø¹Ù†ÙˆØ§Ù† Ø®Ø§Ø¯Ù… Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")

    parser.add_argument("--port", help="Ù…Ù†ÙØ° Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")

    parser.add_argument("--database", help="Ø§Ø³Ù… Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")

    parser.add_argument("--user", help="Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…")

    parser.add_argument("--password", help="ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±")

    parser.add_argument(
        "--report-file",
        default="indexing_report.json",
        help="Ù…Ø³Ø§Ø± Ù…Ù„Ù Ø§Ù„ØªÙ‚Ø±ÙŠØ± (Ø§ÙØªØ±Ø§Ø¶ÙŠ: indexing_report.json)",
    )

    args = parser.parse_args()

    # ØªØ­Ù…ÙŠÙ„ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    db_config = load_database_config(args.config_file)

    # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù…Ù† Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª
    if args.host:
        db_config["host"] = args.host
    if args.port:
        db_config["port"] = args.port
    if args.database:
        db_config["database"] = args.database
    if args.user:
        db_config["user"] = args.user
    if args.password:
        db_config["password"] = args.password

    # ØªØ­Ø¯ÙŠØ¯ Ù…Ù„Ù Ø§Ù„ÙÙ‡Ø§Ø±Ø³
    sql_file = args.sql_file
    if args.simple:
        sql_file = "ULTIMATE_DATABASE_INDEXES_SIMPLE.sql"
        logger.info("ğŸ”§ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ÙÙ‡Ø§Ø±Ø³ Ø§Ù„Ù…Ø¨Ø³Ø·Ø© Ø¨Ø¯ÙˆÙ† CONCURRENTLY")

    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù…Ù„Ù SQL
    if not os.path.exists(sql_file):
        logger.error(f"âŒ Ù…Ù„Ù SQL ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯: {sql_file}")
        sys.exit(1)

    # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¯ÙŠØ± Ø§Ù„ÙÙ‡Ø§Ø±Ø³ ÙˆØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù†Ø¸Ø§Ù…
    manager = UltimateIndexManager(db_config)

    try:
        # Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        if not manager.connect_to_database():
            sys.exit(1)

        # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ÙÙ‡Ø§Ø±Ø³
        success = manager.apply_all_indexes(sql_file)

        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ±
        manager.generate_report(args.report_file)

        # Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
        if success:
            logger.info("ğŸ‰ ØªÙ… ØªØ·Ø¨ÙŠÙ‚ Ù†Ø¸Ø§Ù… Ø§Ù„ÙÙ‡Ø±Ø³Ø© Ø§Ù„Ø´Ø§Ù…Ù„ Ø¨Ù†Ø¬Ø§Ø­!")
            sys.exit(0)
        else:
            logger.error("âŒ ÙØ´Ù„ ÙÙŠ ØªØ·Ø¨ÙŠÙ‚ Ø¨Ø¹Ø¶ Ø§Ù„ÙÙ‡Ø§Ø±Ø³")
            sys.exit(1)

    except KeyboardInterrupt:
        logger.info("â¹ï¸  ØªÙ… Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø¨ÙˆØ§Ø³Ø·Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…")
        sys.exit(1)
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹: {str(e)}")
        sys.exit(1)
    finally:
        manager.disconnect_from_database()


if __name__ == "__main__":
    main()
