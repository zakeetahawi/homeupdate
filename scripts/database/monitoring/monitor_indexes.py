#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Ù†Ø¸Ø§Ù… Ù…Ø±Ø§Ù‚Ø¨Ø© ÙˆÙ…ØªØ§Ø¨Ø¹Ø© Ø§Ù„ÙÙ‡Ø§Ø±Ø³
DATABASE INDEXES MONITORING SYSTEM

Ù‡Ø°Ø§ Ø§Ù„Ø³ÙƒØ±ÙŠØ¨Øª ÙŠØ±Ø§Ù‚Ø¨ Ø£Ø¯Ø§Ø¡ Ø§Ù„ÙÙ‡Ø§Ø±Ø³ ÙˆÙŠÙ‚Ø¯Ù… ØªÙ‚Ø§Ø±ÙŠØ± Ù…ÙØµÙ„Ø©
Ø¹Ù† Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ÙÙ‡Ø§Ø±Ø³ ÙˆØªÙˆØµÙŠØ§Øª Ø§Ù„ØªØ­Ø³ÙŠÙ†
"""

import os
import sys
import json
import psycopg2
from datetime import datetime
from typing import Dict, List, Tuple
import argparse
import logging

# Ø¥Ø¹Ø¯Ø§Ø¯ Ù†Ø¸Ø§Ù… Ø§Ù„Ø³Ø¬Ù„Ø§Øª
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('indexes_monitoring.log', encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

class IndexMonitor:
    """Ù…Ø±Ø§Ù‚Ø¨ Ø§Ù„ÙÙ‡Ø§Ø±Ø³"""
    
    def __init__(self, db_config: Dict[str, str]):
        """ØªÙ‡ÙŠØ¦Ø© Ù…Ø±Ø§Ù‚Ø¨ Ø§Ù„ÙÙ‡Ø§Ø±Ø³"""
        self.db_config = db_config
        self.connection = None
        self.cursor = None
    
    def connect_to_database(self) -> bool:
        """Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        try:
            logger.info("ğŸ”Œ Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...")
            self.connection = psycopg2.connect(
                host=self.db_config['host'],
                port=self.db_config['port'],
                database=self.db_config['database'],
                user=self.db_config['user'],
                password=self.db_config['password']
            )
            self.cursor = self.connection.cursor()
            logger.info("âœ… ØªÙ… Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù†Ø¬Ø§Ø­")
            return True
        except Exception as e:
            logger.error(f"âŒ ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„: {str(e)}")
            return False
    
    def get_index_usage_stats(self) -> List[Dict]:
        """Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ÙÙ‡Ø§Ø±Ø³"""
        try:
            query = """
            SELECT 
                schemaname,
                tablename,
                indexname,
                idx_scan as scans,
                idx_tup_read as tuples_read,
                idx_tup_fetch as tuples_fetched,
                pg_size_pretty(pg_relation_size(indexrelid)) as index_size,
                pg_relation_size(indexrelid) as size_bytes
            FROM pg_stat_user_indexes 
            WHERE schemaname = 'public'
            ORDER BY idx_scan DESC;
            """
            
            self.cursor.execute(query)
            results = []
            
            for row in self.cursor.fetchall():
                results.append({
                    'schema': row[0],
                    'table': row[1],
                    'index': row[2],
                    'scans': row[3] or 0,
                    'tuples_read': row[4] or 0,
                    'tuples_fetched': row[5] or 0,
                    'size_pretty': row[6],
                    'size_bytes': row[7] or 0
                })
            
            return results
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ÙÙ‡Ø§Ø±Ø³: {str(e)}")
            return []
    
    def get_unused_indexes(self, min_scans: int = 10) -> List[Dict]:
        """Ø§Ù„ÙÙ‡Ø§Ø±Ø³ ØºÙŠØ± Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø© Ø£Ùˆ Ù‚Ù„ÙŠÙ„Ø© Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…"""
        try:
            query = """
            SELECT 
                schemaname,
                tablename,
                indexname,
                idx_scan,
                pg_size_pretty(pg_relation_size(indexrelid)) as index_size,
                pg_relation_size(indexrelid) as size_bytes
            FROM pg_stat_user_indexes 
            WHERE schemaname = 'public'
            AND (idx_scan IS NULL OR idx_scan < %s)
            AND indexname NOT LIKE '%%_pkey'
            ORDER BY pg_relation_size(indexrelid) DESC;
            """
            
            self.cursor.execute(query, (min_scans,))
            results = []
            
            for row in self.cursor.fetchall():
                results.append({
                    'schema': row[0],
                    'table': row[1],
                    'index': row[2],
                    'scans': row[3] or 0,
                    'size_pretty': row[4],
                    'size_bytes': row[5] or 0
                })
            
            return results
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ø§Ù„ÙÙ‡Ø§Ø±Ø³ ØºÙŠØ± Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©: {str(e)}")
            return []
    
    def get_table_sizes(self) -> List[Dict]:
        """Ø£Ø­Ø¬Ø§Ù… Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ ÙˆØ§Ù„ÙÙ‡Ø§Ø±Ø³"""
        try:
            query = """
            SELECT 
                schemaname,
                tablename,
                pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) as total_size,
                pg_size_pretty(pg_relation_size(schemaname||'.'||tablename)) as table_size,
                pg_size_pretty(pg_indexes_size(schemaname||'.'||tablename)) as indexes_size,
                pg_total_relation_size(schemaname||'.'||tablename) as total_bytes,
                pg_relation_size(schemaname||'.'||tablename) as table_bytes,
                pg_indexes_size(schemaname||'.'||tablename) as indexes_bytes
            FROM pg_tables 
            WHERE schemaname = 'public'
            ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;
            """
            
            self.cursor.execute(query)
            results = []
            
            for row in self.cursor.fetchall():
                results.append({
                    'schema': row[0],
                    'table': row[1],
                    'total_size': row[2],
                    'table_size': row[3],
                    'indexes_size': row[4],
                    'total_bytes': row[5] or 0,
                    'table_bytes': row[6] or 0,
                    'indexes_bytes': row[7] or 0
                })
            
            return results
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ø£Ø­Ø¬Ø§Ù… Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„: {str(e)}")
            return []
    
    def get_slow_queries(self) -> List[Dict]:
        """Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª Ø§Ù„Ø¨Ø·ÙŠØ¦Ø© (Ø¥Ø°Ø§ ÙƒØ§Ù† pg_stat_statements Ù…ÙØ¹Ù„)"""
        try:
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ pg_stat_statements
            self.cursor.execute("""
                SELECT EXISTS (
                    SELECT 1 FROM pg_extension WHERE extname = 'pg_stat_statements'
                );
            """)
            
            if not self.cursor.fetchone()[0]:
                logger.warning("âš ï¸  pg_stat_statements ØºÙŠØ± Ù…ÙØ¹Ù„")
                return []
            
            query = """
            SELECT 
                query,
                calls,
                total_time,
                mean_time,
                rows
            FROM pg_stat_statements 
            WHERE query NOT LIKE '%pg_stat_statements%'
            ORDER BY mean_time DESC 
            LIMIT 20;
            """
            
            self.cursor.execute(query)
            results = []
            
            for row in self.cursor.fetchall():
                results.append({
                    'query': row[0][:200] + '...' if len(row[0]) > 200 else row[0],
                    'calls': row[1],
                    'total_time': round(row[2], 2),
                    'mean_time': round(row[3], 2),
                    'rows': row[4]
                })
            
            return results
            
        except Exception as e:
            logger.warning(f"âš ï¸  Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø¬Ù„Ø¨ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª Ø§Ù„Ø¨Ø·ÙŠØ¦Ø©: {str(e)}")
            return []
    
    def generate_recommendations(self, unused_indexes: List[Dict], 
                               index_stats: List[Dict]) -> List[str]:
        """Ø¥Ù†Ø´Ø§Ø¡ ØªÙˆØµÙŠØ§Øª Ø§Ù„ØªØ­Ø³ÙŠÙ†"""
        recommendations = []
        
        # ØªÙˆØµÙŠØ§Øª Ù„Ù„ÙÙ‡Ø§Ø±Ø³ ØºÙŠØ± Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©
        if unused_indexes:
            total_unused_size = sum(idx['size_bytes'] for idx in unused_indexes)
            recommendations.append(
                f"ğŸ—‘ï¸  ÙŠÙ…ÙƒÙ† Ø­Ø°Ù {len(unused_indexes)} ÙÙ‡Ø±Ø³ ØºÙŠØ± Ù…Ø³ØªØ®Ø¯Ù… "
                f"Ù„ØªÙˆÙÙŠØ± {self._format_bytes(total_unused_size)} Ù…Ù† Ø§Ù„Ù…Ø³Ø§Ø­Ø©"
            )
            
            # Ø£ÙƒØ¨Ø± Ø§Ù„ÙÙ‡Ø§Ø±Ø³ ØºÙŠØ± Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©
            largest_unused = sorted(unused_indexes, key=lambda x: x['size_bytes'], reverse=True)[:5]
            for idx in largest_unused:
                recommendations.append(
                    f"  - {idx['index']} Ø¹Ù„Ù‰ Ø¬Ø¯ÙˆÙ„ {idx['table']} ({idx['size_pretty']})"
                )
        
        # ØªÙˆØµÙŠØ§Øª Ù„Ù„ÙÙ‡Ø§Ø±Ø³ Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
        high_usage = [idx for idx in index_stats if idx['scans'] > 10000]
        if high_usage:
            recommendations.append(
                f"âš¡ {len(high_usage)} ÙÙ‡Ø±Ø³ Ø¹Ø§Ù„ÙŠ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… - ØªØ£ÙƒØ¯ Ù…Ù† ØµØ­Ø© ØªÙƒÙˆÙŠÙ†Ù‡Ø§"
            )
        
        # ØªÙˆØµÙŠØ§Øª Ø¹Ø§Ù…Ø©
        recommendations.extend([
            "ğŸ“Š Ù‚Ù… Ø¨ØªØ´ØºÙŠÙ„ ANALYZE Ø¨Ø§Ù†ØªØ¸Ø§Ù… Ù„ØªØ­Ø¯ÙŠØ« Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„",
            "ğŸ”„ Ø±Ø§Ù‚Ø¨ Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª Ø¨Ø¹Ø¯ Ø¥Ø¶Ø§ÙØ© ÙÙ‡Ø§Ø±Ø³ Ø¬Ø¯ÙŠØ¯Ø©",
            "ğŸ“ˆ Ø§Ø³ØªØ®Ø¯Ù… EXPLAIN ANALYZE Ù„ØªØ­Ù„ÙŠÙ„ Ø®Ø·Ø· Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…",
            "ğŸ§¹ Ù‚Ù… Ø¨ØªÙ†Ø¸ÙŠÙ Ø§Ù„ÙÙ‡Ø§Ø±Ø³ ØºÙŠØ± Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø© Ø¯ÙˆØ±ÙŠØ§Ù‹"
        ])
        
        return recommendations
    
    def _format_bytes(self, bytes_size: int) -> str:
        """ØªÙ†Ø³ÙŠÙ‚ Ø­Ø¬Ù… Ø§Ù„Ø¨Ø§ÙŠØªØ§Øª"""
        for unit in ['B', 'KB', 'MB', 'GB', 'TB']:
            if bytes_size < 1024.0:
                return f"{bytes_size:.1f} {unit}"
            bytes_size /= 1024.0
        return f"{bytes_size:.1f} PB"
    
    def generate_monitoring_report(self, output_file: str = "indexes_monitoring_report.json"):
        """Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± Ù…Ø±Ø§Ù‚Ø¨Ø© Ø´Ø§Ù…Ù„"""
        try:
            logger.info("ğŸ“Š Ø¬Ø§Ø±ÙŠ Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø©...")
            
            # Ø¬Ù…Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            index_stats = self.get_index_usage_stats()
            unused_indexes = self.get_unused_indexes()
            table_sizes = self.get_table_sizes()
            slow_queries = self.get_slow_queries()
            
            # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙˆØµÙŠØ§Øª
            recommendations = self.generate_recommendations(unused_indexes, index_stats)
            
            # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø¹Ø§Ù…Ø©
            total_indexes = len(index_stats)
            total_unused = len(unused_indexes)
            total_index_size = sum(idx['size_bytes'] for idx in index_stats)
            total_unused_size = sum(idx['size_bytes'] for idx in unused_indexes)
            
            # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ±
            report = {
                'timestamp': datetime.now().isoformat(),
                'database_info': {
                    'host': self.db_config['host'],
                    'database': self.db_config['database']
                },
                'summary': {
                    'total_indexes': total_indexes,
                    'unused_indexes': total_unused,
                    'total_index_size': self._format_bytes(total_index_size),
                    'unused_index_size': self._format_bytes(total_unused_size),
                    'usage_efficiency': round((total_indexes - total_unused) / max(total_indexes, 1) * 100, 2)
                },
                'index_usage_stats': index_stats[:20],  # Ø£ÙØ¶Ù„ 20 ÙÙ‡Ø±Ø³
                'unused_indexes': unused_indexes,
                'table_sizes': table_sizes[:10],  # Ø£ÙƒØ¨Ø± 10 Ø¬Ø¯Ø§ÙˆÙ„
                'slow_queries': slow_queries,
                'recommendations': recommendations
            }
            
            # Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø±ÙŠØ±
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(report, f, ensure_ascii=False, indent=2)
            
            logger.info(f"ğŸ“„ ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø©: {output_file}")
            
            # Ø·Ø¨Ø§Ø¹Ø© Ù…Ù„Ø®Øµ
            self._print_summary(report)
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø©: {str(e)}")
            return False
    
    def _print_summary(self, report: Dict):
        """Ø·Ø¨Ø§Ø¹Ø© Ù…Ù„Ø®Øµ Ø§Ù„ØªÙ‚Ø±ÙŠØ±"""
        summary = report['summary']
        
        print("\n" + "=" * 60)
        print("ğŸ“Š Ù…Ù„Ø®Øµ ØªÙ‚Ø±ÙŠØ± Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„ÙÙ‡Ø§Ø±Ø³")
        print("=" * 60)
        print(f"ğŸ“ˆ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ÙÙ‡Ø§Ø±Ø³: {summary['total_indexes']}")
        print(f"ğŸ—‘ï¸  Ø§Ù„ÙÙ‡Ø§Ø±Ø³ ØºÙŠØ± Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©: {summary['unused_indexes']}")
        print(f"ğŸ’¾ Ø­Ø¬Ù… Ø§Ù„ÙÙ‡Ø§Ø±Ø³ Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ: {summary['total_index_size']}")
        print(f"ğŸ—‘ï¸  Ø­Ø¬Ù… Ø§Ù„ÙÙ‡Ø§Ø±Ø³ ØºÙŠØ± Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©: {summary['unused_index_size']}")
        print(f"âš¡ ÙƒÙØ§Ø¡Ø© Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…: {summary['usage_efficiency']}%")
        
        if report['unused_indexes']:
            print(f"\nğŸ—‘ï¸  Ø£ÙƒØ¨Ø± Ø§Ù„ÙÙ‡Ø§Ø±Ø³ ØºÙŠØ± Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©:")
            for idx in sorted(report['unused_indexes'], key=lambda x: x['size_bytes'], reverse=True)[:5]:
                print(f"  - {idx['index']} ({idx['size_pretty']})")
        
        if report['recommendations']:
            print(f"\nğŸ’¡ Ø§Ù„ØªÙˆØµÙŠØ§Øª:")
            for rec in report['recommendations'][:5]:
                print(f"  {rec}")
        
        print("=" * 60)
    
    def disconnect_from_database(self):
        """Ù‚Ø·Ø¹ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        try:
            if self.cursor:
                self.cursor.close()
            if self.connection:
                self.connection.close()
            logger.info("ğŸ”Œ ØªÙ… Ù‚Ø·Ø¹ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù‚Ø·Ø¹ Ø§Ù„Ø§ØªØµØ§Ù„: {str(e)}")

def load_database_config(config_file: str = None) -> Dict[str, str]:
    """ØªØ­Ù…ÙŠÙ„ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
    default_config = {
        'host': 'localhost',
        'port': '5432',
        'database': 'crm_system',
        'user': 'postgres',
        'password': 'your_password'
    }
    
    if config_file and os.path.exists(config_file):
        try:
            with open(config_file, 'r', encoding='utf-8') as f:
                config = json.load(f)
            logger.info(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù…Ù†: {config_file}")
            return config
        except Exception as e:
            logger.warning(f"âš ï¸  Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª: {str(e)}")
    
    return default_config

def main():
    """Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"""
    parser = argparse.ArgumentParser(
        description='Ù†Ø¸Ø§Ù… Ù…Ø±Ø§Ù‚Ø¨Ø© ÙˆÙ…ØªØ§Ø¨Ø¹Ø© Ø§Ù„ÙÙ‡Ø§Ø±Ø³',
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    
    parser.add_argument(
        '--config-file',
        help='Ù…Ø³Ø§Ø± Ù…Ù„Ù Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (JSON)'
    )
    
    parser.add_argument(
        '--report-file',
        default='indexes_monitoring_report.json',
        help='Ù…Ø³Ø§Ø± Ù…Ù„Ù Ø§Ù„ØªÙ‚Ø±ÙŠØ± (Ø§ÙØªØ±Ø§Ø¶ÙŠ: indexes_monitoring_report.json)'
    )
    
    parser.add_argument(
        '--min-scans',
        type=int,
        default=10,
        help='Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ø¯Ù†Ù‰ Ù„Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø³Ø­Ø§Øª Ù„Ø§Ø¹ØªØ¨Ø§Ø± Ø§Ù„ÙÙ‡Ø±Ø³ Ù…Ø³ØªØ®Ø¯Ù… (Ø§ÙØªØ±Ø§Ø¶ÙŠ: 10)'
    )
    
    args = parser.parse_args()
    
    # ØªØ­Ù…ÙŠÙ„ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    db_config = load_database_config(args.config_file)
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø±Ø§Ù‚Ø¨ Ø§Ù„ÙÙ‡Ø§Ø±Ø³
    monitor = IndexMonitor(db_config)
    
    try:
        # Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        if not monitor.connect_to_database():
            sys.exit(1)
        
        # Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø©
        success = monitor.generate_monitoring_report(args.report_file)
        
        if success:
            logger.info("ğŸ‰ ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø© Ø¨Ù†Ø¬Ø§Ø­!")
            sys.exit(0)
        else:
            logger.error("âŒ ÙØ´Ù„ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø©")
            sys.exit(1)
            
    except KeyboardInterrupt:
        logger.info("â¹ï¸  ØªÙ… Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø¨ÙˆØ§Ø³Ø·Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…")
        sys.exit(1)
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹: {str(e)}")
        sys.exit(1)
    finally:
        monitor.disconnect_from_database()

if __name__ == "__main__":
    main()
