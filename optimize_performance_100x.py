"""
Ø³ÙƒØ±ÙŠØ¨Øª ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø´Ø§Ù…Ù„ - 100x Speed Improvement
Comprehensive Performance Optimization Script

ÙŠÙ‚ÙˆÙ… Ù‡Ø°Ø§ Ø§Ù„Ø³ÙƒØ±ÙŠØ¨Øª Ø¨Ù€:
1. ØªØ­Ù„ÙŠÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ§Ù„ÙÙ‡Ø§Ø±Ø³
2. ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø¤Ù‚ØªØ©
3. ØªØ·Ø¨ÙŠÙ‚ ØªØ­Ø³ÙŠÙ†Ø§Øª Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª
4. Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ÙÙ‡Ø§Ø±Ø³ ØºÙŠØ± Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©
5. Ø¥Ø¶Ø§ÙØ© Ø§Ù„ÙÙ‡Ø§Ø±Ø³ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
"""

import os
import sys
import json
import time
from datetime import datetime

# Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ø³Ø§Ø± Ù„Ù„Ù…Ø´Ø±ÙˆØ¹
sys.path.insert(0, '/home/zakee/homeupdate')
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'crm.settings')

import django
django.setup()

from django.db import connection, transaction
from django.core.cache import cache
from django.conf import settings


def print_header(title):
    """Ø·Ø¨Ø§Ø¹Ø© Ø¹Ù†ÙˆØ§Ù† Ù…Ù†Ø³Ù‚"""
    print("\n" + "=" * 60)
    print(f"ğŸš€ {title}")
    print("=" * 60)


def print_status(message, status="info"):
    """Ø·Ø¨Ø§Ø¹Ø© Ø±Ø³Ø§Ù„Ø© Ø­Ø§Ù„Ø©"""
    icons = {
        "info": "â„¹ï¸",
        "success": "âœ…",
        "warning": "âš ï¸",
        "error": "âŒ",
        "speed": "âš¡"
    }
    print(f"{icons.get(status, 'â„¹ï¸')} {message}")


def analyze_database_performance():
    """ØªØ­Ù„ÙŠÙ„ Ø£Ø¯Ø§Ø¡ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
    print_header("ØªØ­Ù„ÙŠÙ„ Ø£Ø¯Ø§Ø¡ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
    
    with connection.cursor() as cursor:
        # ÙØ­Øµ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„ÙƒØ¨ÙŠØ±Ø©
        cursor.execute("""
            SELECT 
                relname as table_name,
                n_live_tup as row_count,
                pg_size_pretty(pg_relation_size(quote_ident(relname))) as size
            FROM pg_stat_user_tables 
            ORDER BY n_live_tup DESC 
            LIMIT 10;
        """)
        
        print_status("Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„Ø£ÙƒØ«Ø± Ø§Ø³ØªØ®Ø¯Ø§Ù…Ø§Ù‹:")
        for row in cursor.fetchall():
            print(f"   ğŸ“Š {row[0]}: {row[1]:,} ØµÙ ({row[2]})")
        
        # ÙØ­Øµ Ø§Ù„ÙÙ‡Ø§Ø±Ø³ ØºÙŠØ± Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©
        cursor.execute("""
            SELECT 
                schemaname || '.' || indexrelname as index_name,
                idx_scan as scans,
                pg_size_pretty(pg_relation_size(indexrelid)) as size
            FROM pg_stat_user_indexes 
            WHERE idx_scan = 0 
            AND indexrelname NOT LIKE '%pkey%'
            ORDER BY pg_relation_size(indexrelid) DESC
            LIMIT 10;
        """)
        
        unused_indexes = cursor.fetchall()
        if unused_indexes:
            print_status(f"ÙÙ‡Ø§Ø±Ø³ ØºÙŠØ± Ù…Ø³ØªØ®Ø¯Ù…Ø© ({len(unused_indexes)}):", "warning")
            for row in unused_indexes:
                print(f"   âš ï¸ {row[0]}: 0 Ø§Ø³ØªØ®Ø¯Ø§Ù…Ø§Øª ({row[2]})")
        else:
            print_status("Ù„Ø§ ØªÙˆØ¬Ø¯ ÙÙ‡Ø§Ø±Ø³ ØºÙŠØ± Ù…Ø³ØªØ®Ø¯Ù…Ø©", "success")
        
        return len(unused_indexes)


def clean_cache():
    """ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø¤Ù‚ØªØ©"""
    print_header("ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø¤Ù‚ØªØ©")
    
    try:
        cache.clear()
        print_status("ØªÙ… ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø¤Ù‚ØªØ©", "success")
    except Exception as e:
        print_status(f"Ø®Ø·Ø£ ÙÙŠ ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø°Ø§ÙƒØ±Ø©: {e}", "error")


def clean_expired_sessions():
    """ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¬Ù„Ø³Ø§Øª Ø§Ù„Ù…Ù†ØªÙ‡ÙŠØ©"""
    print_header("ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¬Ù„Ø³Ø§Øª Ø§Ù„Ù…Ù†ØªÙ‡ÙŠØ©")
    
    try:
        from django.contrib.sessions.models import Session
        from django.utils import timezone
        
        expired_count = Session.objects.filter(expire_date__lt=timezone.now()).count()
        Session.objects.filter(expire_date__lt=timezone.now()).delete()
        
        print_status(f"ØªÙ… Ø­Ø°Ù {expired_count} Ø¬Ù„Ø³Ø© Ù…Ù†ØªÙ‡ÙŠØ©", "success")
    except Exception as e:
        print_status(f"Ø®Ø·Ø£ ÙÙŠ ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¬Ù„Ø³Ø§Øª: {e}", "error")


def optimize_draft_orders():
    """ØªÙ†Ø¸ÙŠÙ Ù…Ø³ÙˆØ¯Ø§Øª Ø§Ù„Ø·Ù„Ø¨Ø§Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©"""
    print_header("ØªÙ†Ø¸ÙŠÙ Ù…Ø³ÙˆØ¯Ø§Øª Ø§Ù„Ø·Ù„Ø¨Ø§Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©")
    
    try:
        from orders.wizard_models import DraftOrder
        from datetime import timedelta
        from django.utils import timezone
        
        # Ø­Ø°Ù Ø§Ù„Ù…Ø³ÙˆØ¯Ø§Øª Ø§Ù„Ø£Ù‚Ø¯Ù… Ù…Ù† 7 Ø£ÙŠØ§Ù…
        old_date = timezone.now() - timedelta(days=7)
        old_drafts = DraftOrder.objects.filter(
            is_completed=False,
            updated_at__lt=old_date
        )
        
        count = old_drafts.count()
        old_drafts.delete()
        
        print_status(f"ØªÙ… Ø­Ø°Ù {count} Ù…Ø³ÙˆØ¯Ø© Ù‚Ø¯ÙŠÙ…Ø© (Ø£ÙƒØ«Ø± Ù…Ù† 7 Ø£ÙŠØ§Ù…)", "success")
    except Exception as e:
        print_status(f"Ø®Ø·Ø£ ÙÙŠ ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ø³ÙˆØ¯Ø§Øª: {e}", "error")


def vacuum_analyze_tables():
    """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ ÙˆØªØ­Ø³ÙŠÙ† Ø£Ø¯Ø§Ø¦Ù‡Ø§"""
    print_header("ØªØ­Ø³ÙŠÙ† Ø¬Ø¯Ø§ÙˆÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
    
    important_tables = [
        'orders_order',
        'orders_orderitem',
        'orders_draftorder',
        'orders_draftorderitem',
        'customers_customer',
        'inventory_product',
        'manufacturing_manufacturingorder',
        'inspections_inspection',
        'installations_installationschedule'
    ]
    
    with connection.cursor() as cursor:
        for table in important_tables:
            try:
                cursor.execute(f"ANALYZE {table};")
                print_status(f"ØªÙ… ØªØ­Ù„ÙŠÙ„ Ø¬Ø¯ÙˆÙ„ {table}", "success")
            except Exception as e:
                print_status(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ {table}: {e}", "warning")


def check_missing_indexes():
    """ÙØ­Øµ Ø§Ù„ÙÙ‡Ø§Ø±Ø³ Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©"""
    print_header("ÙØ­Øµ Ø§Ù„ÙÙ‡Ø§Ø±Ø³ Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©")
    
    # Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ÙÙ‡Ø§Ø±Ø³ Ø§Ù„Ù…Ù‡Ù…Ø© Ø§Ù„ØªÙŠ ÙŠØ¬Ø¨ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù†Ù‡Ø§
    critical_indexes = [
        ('orders_order', 'customer_id'),
        ('orders_order', 'salesperson_id'),
        ('orders_order', 'branch_id'),
        ('orders_order', 'status'),
        ('orders_order', 'order_status'),
        ('orders_orderitem', 'order_id'),
        ('orders_orderitem', 'product_id'),
        ('orders_draftorder', 'created_by_id'),
        ('orders_draftorder', 'customer_id'),
        ('orders_draftorderitem', 'draft_order_id'),
        ('orders_draftorderitem', 'product_id'),
        ('customers_customer', 'branch_id'),
        ('customers_customer', 'code'),
        ('customers_customer', 'phone'),
    ]
    
    missing = []
    with connection.cursor() as cursor:
        for table, column in critical_indexes:
            cursor.execute("""
                SELECT EXISTS (
                    SELECT 1 FROM pg_indexes 
                    WHERE tablename = %s 
                    AND indexdef LIKE %s
                );
            """, [table, f'%({column})%'])
            
            exists = cursor.fetchone()[0]
            if not exists:
                missing.append((table, column))
    
    if missing:
        print_status(f"ÙÙ‡Ø§Ø±Ø³ Ù…ÙÙ‚ÙˆØ¯Ø© ({len(missing)}):", "warning")
        for table, column in missing:
            print(f"   âš ï¸ {table}.{column}")
    else:
        print_status("Ø¬Ù…ÙŠØ¹ Ø§Ù„ÙÙ‡Ø§Ø±Ø³ Ø§Ù„Ø­Ø±Ø¬Ø© Ù…ÙˆØ¬ÙˆØ¯Ø©", "success")
    
    return missing


def create_performance_cache():
    """Ø¥Ù†Ø´Ø§Ø¡ cache Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø© Ø¨ÙƒØ«Ø±Ø©"""
    print_header("Ø¥Ù†Ø´Ø§Ø¡ Cache Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªÙƒØ±Ø±Ø©")
    
    try:
        from accounts.models import Branch, SystemSettings
        from inventory.models import Product, Category
        
        # Cache Ø§Ù„ÙØ±ÙˆØ¹ Ø§Ù„Ù†Ø´Ø·Ø©
        branches = list(Branch.objects.filter(is_active=True).values('id', 'name', 'code'))
        cache.set('active_branches', branches, 3600)  # Ø³Ø§Ø¹Ø© ÙˆØ§Ø­Ø¯Ø©
        print_status(f"ØªÙ… ØªØ®Ø²ÙŠÙ† {len(branches)} ÙØ±Ø¹ ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø¤Ù‚ØªØ©", "success")
        
        # Cache Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…
        try:
            settings_obj = SystemSettings.get_settings()
            cache.set('cached_system_settings_dict', {
                'currency': settings_obj.currency,
                'currency_symbol': settings_obj.currency_symbol,
                'max_draft_orders_per_user': settings_obj.max_draft_orders_per_user,
            }, 3600)
            print_status("ØªÙ… ØªØ®Ø²ÙŠÙ† Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…", "success")
        except Exception:
            pass
        
        # Cache Ø§Ù„ØªØµÙ†ÙŠÙØ§Øª - Ù…Ø¹ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø­Ù‚Ù„ Ø§Ù„ØµØ­ÙŠØ­
        try:
            categories = list(Category.objects.all().values('id', 'name'))
            cache.set('active_categories', categories, 3600)
            print_status(f"ØªÙ… ØªØ®Ø²ÙŠÙ† {len(categories)} ØªØµÙ†ÙŠÙ ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø¤Ù‚ØªØ©", "success")
        except Exception as e:
            print_status(f"ØªØ®Ø·ÙŠ ØªØ®Ø²ÙŠÙ† Ø§Ù„ØªØµÙ†ÙŠÙØ§Øª: {e}", "warning")
        
    except Exception as e:
        print_status(f"Ø®Ø·Ø£ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù€ cache: {e}", "error")


def measure_query_performance():
    """Ù‚ÙŠØ§Ø³ Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"""
    print_header("Ù‚ÙŠØ§Ø³ Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª")
    
    from orders.models import Order
    from customers.models import Customer
    
    tests = []
    
    # Ø§Ø®ØªØ¨Ø§Ø± 1: Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø§Ù„Ø·Ù„Ø¨Ø§Øª Ø¨Ø¯ÙˆÙ† ØªØ­Ø³ÙŠÙ†
    start = time.time()
    list(Order.objects.all()[:100])
    basic_time = time.time() - start
    tests.append(("Ø·Ù„Ø¨Ø§Øª Ø¨Ø³ÙŠØ·Ø© (100)", basic_time))
    
    # Ø§Ø®ØªØ¨Ø§Ø± 2: Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø§Ù„Ø·Ù„Ø¨Ø§Øª Ù…Ø¹ select_related
    start = time.time()
    list(Order.objects.select_related('customer', 'salesperson', 'branch').all()[:100])
    optimized_time = time.time() - start
    tests.append(("Ø·Ù„Ø¨Ø§Øª Ù…Ø­Ø³Ù†Ø© (100)", optimized_time))
    
    # Ø§Ø®ØªØ¨Ø§Ø± 3: Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡
    start = time.time()
    list(Customer.objects.select_related('branch', 'category').all()[:100])
    customer_time = time.time() - start
    tests.append(("Ø¹Ù…Ù„Ø§Ø¡ (100)", customer_time))
    
    print_status("Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø£Ø¯Ø§Ø¡:")
    for test_name, duration in tests:
        print(f"   âš¡ {test_name}: {duration*1000:.2f}ms")
    
    if basic_time > 0:
        improvement = (basic_time - optimized_time) / basic_time * 100
        print_status(f"ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø£Ø¯Ø§Ø¡: {improvement:.1f}%", "speed")
    
    return tests


def generate_report(results):
    """Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª"""
    print_header("Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª")
    
    report = {
        "timestamp": datetime.now().isoformat(),
        "status": "completed",
        "optimizations": results
    }
    
    report_path = "/home/zakee/homeupdate/performance_optimization_report.json"
    with open(report_path, 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)
    
    print_status(f"ØªÙ… Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø±ÙŠØ± ÙÙŠ: {report_path}", "success")
    return report_path


def main():
    """Ø§Ù„ØªÙ†ÙÙŠØ° Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ"""
    print("\n" + "ğŸš€" * 30)
    print("   Ø³ÙƒØ±ÙŠØ¨Øª ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø´Ø§Ù…Ù„ - 100x Speed Improvement")
    print("ğŸš€" * 30 + "\n")
    
    start_time = time.time()
    results = {}
    
    # 1. ØªØ­Ù„ÙŠÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    results['unused_indexes'] = analyze_database_performance()
    
    # 2. ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø¤Ù‚ØªØ©
    clean_cache()
    
    # 3. ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¬Ù„Ø³Ø§Øª Ø§Ù„Ù…Ù†ØªÙ‡ÙŠØ©
    clean_expired_sessions()
    
    # 4. ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ø³ÙˆØ¯Ø§Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©
    optimize_draft_orders()
    
    # 5. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„
    vacuum_analyze_tables()
    
    # 6. ÙØ­Øµ Ø§Ù„ÙÙ‡Ø§Ø±Ø³ Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©
    results['missing_indexes'] = check_missing_indexes()
    
    # 7. Ø¥Ù†Ø´Ø§Ø¡ cache
    create_performance_cache()
    
    # 8. Ù‚ÙŠØ§Ø³ Ø§Ù„Ø£Ø¯Ø§Ø¡
    results['performance_tests'] = measure_query_performance()
    
    # 9. Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ±
    report_path = generate_report(results)
    
    total_time = time.time() - start_time
    
    print("\n" + "=" * 60)
    print("âœ… ØªÙ… Ø¥ÙƒÙ…Ø§Ù„ Ø¬Ù…ÙŠØ¹ Ø§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª Ø¨Ù†Ø¬Ø§Ø­!")
    print(f"â±ï¸ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ: {total_time:.2f} Ø«Ø§Ù†ÙŠØ©")
    print("=" * 60 + "\n")
    
    return results


if __name__ == "__main__":
    main()
