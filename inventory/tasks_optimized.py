"""
Ù…Ù‡Ø§Ù… Celery Ø§Ù„Ù…Ø­Ø³Ù‘Ù†Ø© Ù„Ù„Ù…Ø®Ø²ÙˆÙ† - Ù†Ø¸Ø§Ù… Ø°ÙƒÙŠ ÙŠÙ…Ù†Ø¹ Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª
"""

from celery import shared_task
from django.contrib.auth import get_user_model
from django.utils import timezone
from django.db import transaction
from decimal import Decimal
import logging
import pandas as pd
from io import BytesIO

User = get_user_model()
logger = logging.getLogger(__name__)


@shared_task(bind=True, time_limit=600, soft_time_limit=540, rate_limit=None)
def bulk_upload_products_fast(self, upload_log_id, file_content, warehouse_id, upload_mode, user_id, auto_delete_empty=False):
    """
    Ø±ÙØ¹ Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª Ø¨Ø§Ù„Ø¬Ù…Ù„Ø© - Ù†Ø¸Ø§Ù… Ø°ÙƒÙŠ Ù…Ø­Ø³Ù‘Ù†
    Ø§Ù„Ø£ÙˆØ¶Ø§Ø¹:
    - smart_update: ØªØ­Ø¯ÙŠØ« Ø°ÙƒÙŠ Ù…Ø¹ Ù†Ù‚Ù„ Ù„Ù„Ù…Ø³ØªÙˆØ¯Ø¹ Ø§Ù„ØµØ­ÙŠØ­
    - merge_warehouses: Ø¯Ù…Ø¬ Ø§Ù„Ø£ØµÙ†Ø§Ù Ø§Ù„Ù…ÙƒØ±Ø±Ø©  
    - add_only: Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø¬Ø¯ÙŠØ¯ ÙÙ‚Ø·
    - clean_start: Ù…Ø³Ø­ ÙƒØ§Ù…Ù„ ÙˆØ¨Ø¯Ø¡ Ù…Ù† Ø¬Ø¯ÙŠØ¯
    
    Args:
        auto_delete_empty: Ø­Ø°Ù Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹Ø§Øª Ø§Ù„ÙØ§Ø±ØºØ© Ø¨Ø¹Ø¯ Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡
    """
    from .models import (BulkUploadLog, Product, Category, Warehouse, 
                         StockTransaction, BulkUploadError)
    from .smart_upload_logic import (smart_update_product, clean_start_reset,
                                     add_stock_transaction, delete_empty_warehouses)
    
    logger.info(f"ğŸš€ Ø¨Ø¯Ø¡ Ø§Ù„Ø±ÙØ¹ Ø§Ù„Ø°ÙƒÙŠ - Log: {upload_log_id} - Ø§Ù„ÙˆØ¶Ø¹: {upload_mode}")
    
    try:
        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© (Ø¨Ø¯ÙˆÙ† select_for_update)
        upload_log = BulkUploadLog.objects.get(id=upload_log_id)
        user = User.objects.get(id=user_id)
        warehouse = Warehouse.objects.get(id=warehouse_id) if warehouse_id else None
        
        upload_log.status = 'processing'
        upload_log.save(update_fields=['status'])
        
        # Ù‚Ø±Ø§Ø¡Ø© Excel Ø¨Ø³Ø±Ø¹Ø©
        logger.info("ğŸ“Š Ù‚Ø±Ø§Ø¡Ø© Excel...")
        df = pd.read_excel(BytesIO(file_content), engine='openpyxl')
        total = len(df)
        upload_log.total_rows = total
        upload_log.save(update_fields=['total_rows'])
        
        logger.info(f"ğŸ“‹ {total} ØµÙ Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©")
        
        # ØªÙ‡ÙŠØ¦Ø© ÙƒØ§Ù…Ù„Ø© Ø¥Ø°Ø§ Ø·ÙÙ„Ø¨
        if upload_mode == 'clean_start':
            logger.warning("âš ï¸ ÙˆØ¶Ø¹ Ø§Ù„Ù…Ø³Ø­ Ø§Ù„ÙƒØ§Ù…Ù„")
            reset_stats = clean_start_reset()
            upload_log.summary = f"Ù…Ø³Ø­ ÙƒØ§Ù…Ù„: {reset_stats['deleted_products']} Ù…Ù†ØªØ¬ØŒ {reset_stats['deleted_transactions']} Ù…Ø¹Ø§Ù…Ù„Ø©"
            upload_log.save(update_fields=['summary'])
        
        # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        df = df.dropna(subset=['Ø§Ø³Ù… Ø§Ù„Ù…Ù†ØªØ¬', 'Ø§Ù„Ø³Ø¹Ø±']).fillna('')
        
        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³Ø¨Ù‚Ø©
        categories_cache = {c.name: c for c in Category.objects.all()}
        warehouses_cache = {w.name: w for w in Warehouse.objects.filter(is_active=True)}
        
        stats = {
            'created': 0, 
            'updated': 0, 
            'moved': 0, 
            'merged': 0, 
            'skipped': 0, 
            'errors': 0,
            'cutting_updated': 0,
            'cutting_split': 0
        }
        
        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¨Ø¯ÙØ¹Ø§Øª Ø³Ø±ÙŠØ¹Ø©
        batch_size = 100
        errors_batch = []  # Ù„Ø­ÙØ¸ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø¨Ø§Ù„Ø¯ÙØ¹Ø©
        
        for batch_start in range(0, len(df), batch_size):
            batch_end = min(batch_start + batch_size, len(df))
            batch = df.iloc[batch_start:batch_end]
            
            with transaction.atomic():
                for idx, row in batch.iterrows():
                    try:
                        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
                        name = str(row['Ø§Ø³Ù… Ø§Ù„Ù…Ù†ØªØ¬']).strip()
                        code = str(row.get('Ø§Ù„ÙƒÙˆØ¯', '')).strip() or None
                        price = float(row['Ø§Ù„Ø³Ø¹Ø±']) if row['Ø§Ù„Ø³Ø¹Ø±'] else 0
                        quantity = float(row.get('Ø§Ù„ÙƒÙ…ÙŠØ©', 0)) if pd.notna(row.get('Ø§Ù„ÙƒÙ…ÙŠØ©')) else 0
                        
                        if not name or price <= 0:
                            stats['errors'] += 1
                            errors_batch.append(BulkUploadError(
                                upload_log=upload_log,
                                row_number=idx + 2,
                                error_type='missing_data',
                                result_status='failed',
                                error_message='Ø§Ø³Ù… Ø§Ù„Ù…Ù†ØªØ¬ Ø£Ùˆ Ø§Ù„Ø³Ø¹Ø± Ù…ÙÙ‚ÙˆØ¯ Ø£Ùˆ ØºÙŠØ± ØµØ§Ù„Ø­',
                                row_data=row.to_dict()
                            ))
                            continue
                        
                        # Ø§Ù„ÙØ¦Ø©
                        cat_name = str(row.get('Ø§Ù„ÙØ¦Ø©', '')).strip()
                        category = None
                        if cat_name:
                            if cat_name in categories_cache:
                                category = categories_cache[cat_name]
                            else:
                                category = Category.objects.create(name=cat_name)
                                categories_cache[cat_name] = category
                        
                        # Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹ Ø§Ù„Ù…Ø³ØªÙ‡Ø¯Ù
                        wh_name = str(row.get('Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹', '')).strip()
                        target_wh = warehouse
                        
                        if wh_name:
                            if wh_name in warehouses_cache:
                                target_wh = warehouses_cache[wh_name]
                            else:
                                target_wh = Warehouse.objects.create(
                                    name=wh_name,
                                    code=f"WH{len(warehouses_cache)+1:03d}",
                                    is_active=True,
                                    created_by=user
                                )
                                warehouses_cache[wh_name] = target_wh
                        
                        # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ù†Ø·Ù‚ Ø§Ù„Ø°ÙƒÙŠ
                        product_data = {
                            'name': name,
                            'code': code,
                            'price': price,
                            'category': category,
                            'quantity': quantity,
                            'currency': row.get('Ø§Ù„Ø¹Ù…Ù„Ø©', 'EGP'),
                            'unit': row.get('Ø§Ù„ÙˆØ­Ø¯Ø©', 'piece')
                        }
                        
                        result = smart_update_product(product_data, target_wh, user, upload_mode)
                        
                        # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
                        if result['action'] == 'created':
                            stats['created'] += 1
                        elif result['action'] == 'updated':
                            stats['updated'] += 1
                        elif result['action'] == 'moved':
                            stats['moved'] += 1
                            stats['updated'] += 1
                        elif result['action'] == 'skipped':
                            stats['skipped'] += 1
                            errors_batch.append(BulkUploadError(
                                upload_log=upload_log,
                                row_number=idx + 2,
                                error_type='duplicate',
                                result_status='skipped',
                                error_message=result['message'],
                                row_data=row.to_dict()
                            ))
                        
                        # ØªØªØ¨Ø¹ ØªØ­Ø¯ÙŠØ«Ø§Øª Ø£ÙˆØ§Ù…Ø± Ø§Ù„ØªÙ‚Ø·ÙŠØ¹ ğŸ”¥
                        if 'cutting_orders_updated' in result:
                            stats['cutting_updated'] += result['cutting_orders_updated']
                        if 'cutting_orders_split' in result:
                            stats['cutting_split'] += result['cutting_orders_split']
                        
                        # Ø¥Ø¶Ø§ÙØ© Ø§Ù„ÙƒÙ…ÙŠØ© Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù…ÙˆØ¬ÙˆØ¯Ø© (ÙÙ‚Ø· Ø¥Ø°Ø§ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ù†Ù‚Ù„)
                        if quantity > 0 and result['product'] and target_wh and result['action'] != 'moved':
                            add_stock_transaction(result['product'], target_wh, quantity, user, 'Ø±ÙØ¹ Ù…Ù† Excel')
                    
                    except Exception as e:
                        logger.error(f"Ø®Ø·Ø£ ØµÙ {idx}: {e}")
                        stats['errors'] += 1
                        errors_batch.append(BulkUploadError(
                            upload_log=upload_log,
                            row_number=idx + 2,
                            error_type='processing',
                            result_status='failed',
                            error_message=str(e),
                            row_data=row.to_dict() if hasattr(row, 'to_dict') else {}
                        ))
            
            # Ø­ÙØ¸ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø¨Ø§Ù„Ø¯ÙØ¹Ø©
            if errors_batch:
                BulkUploadError.objects.bulk_create(errors_batch)
                errors_batch = []
            
            # ØªØ­Ø¯ÙŠØ« Ø§Ù„ØªÙ‚Ø¯Ù…
            processed = batch_end
            upload_log.processed_count = processed
            upload_log.created_count = stats['created']
            upload_log.updated_count = stats['updated']
            upload_log.skipped_count = stats['skipped']
            upload_log.error_count = stats['errors']
            upload_log.save(update_fields=[
                'processed_count', 'created_count', 'updated_count',
                'skipped_count', 'error_count'
            ])
            
            # ØªØ­Ø¯ÙŠØ« Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ù‡Ù…Ø©
            percent = int((processed / total) * 100)
            self.update_state(
                state='PROGRESS',
                meta={
                    'current': processed,
                    'total': total,
                    'percent': percent,
                    'created': stats['created'],
                    'updated': stats['updated'],
                    'skipped': stats['skipped'],
                    'errors': stats['errors']
                }
            )
            
            logger.info(f"âœ… {percent}% - {processed}/{total}")
        
        # Ø¥ÙƒÙ…Ø§Ù„
        summary_parts = []
        if stats['created'] > 0:
            summary_parts.append(f"âœ… {stats['created']} Ù…Ù†ØªØ¬ Ø¬Ø¯ÙŠØ¯")
        if stats['updated'] > 0:
            summary_parts.append(f"ğŸ”„ {stats['updated']} Ù…Ø­Ø¯Ø«")
        if stats['moved'] > 0:
            summary_parts.append(f"ğŸ“¦ {stats['moved']} Ù†ÙÙ‚Ù„ Ù„Ù„Ù…Ø³ØªÙˆØ¯Ø¹ Ø§Ù„ØµØ­ÙŠØ­")
        if stats['cutting_updated'] > 0:
            summary_parts.append(f"ğŸ”ª {stats['cutting_updated']} Ø£Ù…Ø± ØªÙ‚Ø·ÙŠØ¹ Ù…Ø­Ø¯Ø«")
        if stats['cutting_split'] > 0:
            summary_parts.append(f"ğŸ”€ {stats['cutting_split']} Ø£Ù…Ø± ØªÙ‚Ø·ÙŠØ¹ Ù…Ù†Ù‚Ø³Ù…")
        if stats['skipped'] > 0:
            summary_parts.append(f"â­ï¸ {stats['skipped']} Ù…ØªØ®Ø·Ù‰")
        if stats['errors'] > 0:
            summary_parts.append(f"âŒ {stats['errors']} Ø®Ø·Ø£")
        
        summary = " | ".join(summary_parts) if summary_parts else "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª"
        
        upload_log.complete(summary=summary)
        
        logger.info("ğŸ‰ Ø§ÙƒØªÙ…Ù„ Ø§Ù„Ø±ÙØ¹ Ø¨Ù†Ø¬Ø§Ø­!")
        
        # Ø­Ø°Ù Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹Ø§Øª Ø§Ù„ÙØ§Ø±ØºØ© Ø¥Ø°Ø§ Ø·ÙÙ„Ø¨ Ø°Ù„Ùƒ
        deleted_warehouses = []
        if auto_delete_empty:
            logger.info("ğŸ—‘ï¸ Ø¨Ø¯Ø¡ Ø­Ø°Ù Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹Ø§Øª Ø§Ù„ÙØ§Ø±ØºØ©...")
            delete_result = delete_empty_warehouses(user)
            deleted_warehouses = delete_result.get('warehouses', [])
            
            if deleted_warehouses:
                logger.info(f"âœ… ØªÙ… Ø­Ø°Ù {len(deleted_warehouses)} Ù…Ø³ØªÙˆØ¯Ø¹: {', '.join(deleted_warehouses)}")
                upload_log.summary = summary + f" | ğŸ—‘ï¸ Ø­ÙØ°Ù {len(deleted_warehouses)} Ù…Ø³ØªÙˆØ¯Ø¹ ÙØ§Ø±Øº"
                upload_log.save(update_fields=['summary'])
        
        return {
            'status': 'success',
            'stats': stats,
            'upload_log_id': upload_log_id,
            'deleted_warehouses': deleted_warehouses
        }
    
    except Exception as e:
        logger.error(f"ğŸ’¥ Ø®Ø·Ø£ ÙƒØ§Ø±Ø«ÙŠ: {e}")
        upload_log.fail(error_message=str(e))
        raise
