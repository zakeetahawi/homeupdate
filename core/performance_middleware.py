"""
ğŸ›¡ï¸ Performance Middleware - Ù…ÙŠØ¯Ù„ÙˆÙŠØ± ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø£Ø¯Ø§Ø¡
ÙŠÙ‚ÙˆÙ… Ø¨Ù€:
1. Smart Caching Ù„Ù„ØµÙØ­Ø§Øª
2. Query Monitoring & Logging
3. Response Time Tracking
4. Automatic N+1 Detection
"""

import hashlib
import logging
import re
import time
from typing import Callable

from django.conf import settings
from django.core.cache import cache
from django.db import connection, reset_queries
from django.http import HttpRequest, HttpResponse

logger = logging.getLogger("performance")


class PerformanceCacheMiddleware:
    """
    Ù…ÙŠØ¯Ù„ÙˆÙŠØ± Ø§Ù„ÙƒØ§Ø´ Ø§Ù„Ø°ÙƒÙŠ Ù„Ù„Ø£Ø¯Ø§Ø¡

    Ø§Ù„Ù…Ù…ÙŠØ²Ø§Øª:
    - ÙƒØ§Ø´ ØªÙ„Ù‚Ø§Ø¦ÙŠ Ù„Ù„ØµÙØ­Ø§Øª GET
    - ØªØ¬Ø§Ù‡Ù„ ØµÙØ­Ø§Øª Ù…Ø¹ÙŠÙ†Ø© (admin, login, etc.)
    - vary by user/branch
    - ETag support
    """

    # ØµÙØ­Ø§Øª Ù„Ø§ ÙŠØªÙ… ÙƒØ§Ø´Ù‡Ø§ Ø£Ø¨Ø¯Ø§Ù‹
    NEVER_CACHE_PATHS = [
        r"^/admin/",
        r"^/accounts/login/",
        r"^/accounts/logout/",
        r"^/api/.*",  # API ÙŠØªÙ… ÙƒØ§Ø´Ù‡ Ø¨Ø´ÙƒÙ„ Ù…Ù†ÙØµÙ„
        r".*\?.*no_cache=",
    ]

    # ØµÙØ­Ø§Øª ÙŠØªÙ… ÙƒØ§Ø´Ù‡Ø§ Ù„ÙØªØ±Ø© Ù‚ØµÙŠØ±Ø© (1 Ø¯Ù‚ÙŠÙ‚Ø©)
    SHORT_CACHE_PATHS = [
        (r"^/orders/wizard/", 60),
        (r"^/notifications/", 30),
    ]

    # ØµÙØ­Ø§Øª ÙŠØªÙ… ÙƒØ§Ø´Ù‡Ø§ Ù„ÙØªØ±Ø© Ù…ØªÙˆØ³Ø·Ø© (5 Ø¯Ù‚Ø§Ø¦Ù‚)
    MEDIUM_CACHE_PATHS = [
        (r"^/installations/installation-list/", 300),
        (r"^/orders/order-list/", 300),
        (r"^/manufacturing/", 300),
    ]

    # ØµÙØ­Ø§Øª ÙŠØªÙ… ÙƒØ§Ø´Ù‡Ø§ Ù„ÙØªØ±Ø© Ø·ÙˆÙŠÙ„Ø© (30 Ø¯Ù‚ÙŠÙ‚Ø©)
    LONG_CACHE_PATHS = [
        (r"^/reports/", 1800),
        (r"^/statistics/", 1800),
    ]

    def __init__(self, get_response: Callable):
        self.get_response = get_response

    def __call__(self, request: HttpRequest) -> HttpResponse:
        # ØªØ¬Ø§Ù‡Ù„ ØºÙŠØ± GET
        if request.method != "GET":
            return self.get_response(request)

        # ØªØ¬Ø§Ù‡Ù„ AJAX requests Ù„Ù„Ù€ polling
        if request.headers.get("X-Requested-With") == "XMLHttpRequest":
            if "poll" in request.path or "status" in request.path:
                return self.get_response(request)

        # ÙØ­Øµ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù…Ø³Ø§Ø± ÙÙŠ Ù‚Ø§Ø¦Ù…Ø© Ø¹Ø¯Ù… Ø§Ù„ÙƒØ§Ø´
        for pattern in self.NEVER_CACHE_PATHS:
            if re.match(pattern, request.path):
                return self.get_response(request)

        # ØªØ­Ø¯ÙŠØ¯ Ù…Ø¯Ø© Ø§Ù„ÙƒØ§Ø´
        cache_timeout = self._get_cache_timeout(request.path)
        if cache_timeout == 0:
            return self.get_response(request)

        # Ø¨Ù†Ø§Ø¡ Ù…ÙØªØ§Ø­ Ø§Ù„ÙƒØ§Ø´
        cache_key = self._build_cache_key(request)

        # Ù…Ø­Ø§ÙˆÙ„Ø© Ø¬Ù„Ø¨ Ù…Ù† Ø§Ù„ÙƒØ§Ø´
        cached_response = cache.get(cache_key)
        if cached_response is not None:
            # Ø¥Ø¶Ø§ÙØ© header Ù„Ù„ØªÙˆØ¶ÙŠØ­
            response = cached_response
            response["X-Cache"] = "HIT"
            return response

        # ØªÙ†ÙÙŠØ° Ø§Ù„Ø·Ù„Ø¨
        response = self.get_response(request)

        # ØªØ®Ø²ÙŠÙ† ÙÙ‚Ø· Ù„Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø§Øª Ø§Ù„Ù†Ø§Ø¬Ø­Ø©
        if response.status_code == 200 and not response.streaming:
            try:
                cache.set(cache_key, response, cache_timeout)
                response["X-Cache"] = "MISS"
            except Exception as e:
                logger.warning(f"Failed to cache response: {e}")

        return response

    def _get_cache_timeout(self, path: str) -> int:
        """ØªØ­Ø¯ÙŠØ¯ Ù…Ø¯Ø© Ø§Ù„ÙƒØ§Ø´ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø³Ø§Ø±"""
        for pattern, timeout in self.SHORT_CACHE_PATHS:
            if re.match(pattern, path):
                return timeout

        for pattern, timeout in self.MEDIUM_CACHE_PATHS:
            if re.match(pattern, path):
                return timeout

        for pattern, timeout in self.LONG_CACHE_PATHS:
            if re.match(pattern, path):
                return timeout

        # Ø§ÙØªØ±Ø§Ø¶ÙŠ: 2 Ø¯Ù‚ÙŠÙ‚Ø©
        return 120

    def _build_cache_key(self, request: HttpRequest) -> str:
        """Ø¨Ù†Ø§Ø¡ Ù…ÙØªØ§Ø­ Ø§Ù„ÙƒØ§Ø´"""
        parts = [
            "page",
            request.path,
        ]

        # Ø¥Ø¶Ø§ÙØ© query string
        if request.GET:
            qs_hash = hashlib.md5(request.GET.urlencode().encode()).hexdigest()[:8]
            parts.append(qs_hash)

        # vary by user
        if hasattr(request, "user") and request.user.is_authenticated:
            parts.append(f"u:{request.user.id}")
            # vary by branch if available
            if hasattr(request.user, "branch_id") and request.user.branch_id:
                parts.append(f"b:{request.user.branch_id}")

        return ":".join(parts)


class QueryMonitorMiddleware:
    """
    Ù…ÙŠØ¯Ù„ÙˆÙŠØ± Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª

    Ø§Ù„Ù…Ù…ÙŠØ²Ø§Øª:
    - ØªØ³Ø¬ÙŠÙ„ Ø¹Ø¯Ø¯ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª Ù„ÙƒÙ„ Ø·Ù„Ø¨
    - ØªØ­Ø°ÙŠØ± Ø¹Ù†Ø¯ ØªØ¬Ø§ÙˆØ² Ø§Ù„Ø­Ø¯ Ø§Ù„Ù…Ø³Ù…ÙˆØ­
    - Ø§ÙƒØªØ´Ø§Ù N+1 queries
    - ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª Ø§Ù„Ø¨Ø·ÙŠØ¦Ø©
    """

    # Ø¹ØªØ¨Ø§Øª Ø§Ù„ØªØ­Ø°ÙŠØ±
    QUERY_COUNT_WARNING = 50
    QUERY_COUNT_CRITICAL = 100
    QUERY_TIME_WARNING_MS = 100
    TOTAL_TIME_WARNING_MS = 2000

    def __init__(self, get_response: Callable):
        self.get_response = get_response

    def __call__(self, request: HttpRequest) -> HttpResponse:
        # ØªØ¬Ø§Ù‡Ù„ static files
        if self._is_static_request(request):
            return self.get_response(request)

        # Ø¨Ø¯Ø¡ Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø©
        start_time = time.time()
        reset_queries()

        # ØªÙØ¹ÙŠÙ„ debug cursor Ù„ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª
        was_debug = settings.DEBUG
        if not was_debug:
            connection.force_debug_cursor = True

        try:
            response = self.get_response(request)
        finally:
            # Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ø¶Ø¨Ø·
            if not was_debug:
                connection.force_debug_cursor = False

        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
        total_time = (time.time() - start_time) * 1000
        queries = connection.queries
        query_count = len(queries)

        # Ø¥Ø¶Ø§ÙØ© headers Ù„Ù„ØªÙˆØ¶ÙŠØ­
        response["X-Query-Count"] = str(query_count)
        response["X-Response-Time"] = f"{total_time:.0f}ms"

        # ØªØ­Ù„ÙŠÙ„ ÙˆØªØ³Ø¬ÙŠÙ„
        self._analyze_and_log(request, queries, query_count, total_time)

        return response

    def _is_static_request(self, request: HttpRequest) -> bool:
        """ÙØ­Øµ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø·Ù„Ø¨ Ù„Ù…Ù„Ù Ø«Ø§Ø¨Øª"""
        static_patterns = ["/static/", "/media/", "/favicon.ico"]
        return any(request.path.startswith(p) for p in static_patterns)

    def _analyze_and_log(
        self, request: HttpRequest, queries: list, query_count: int, total_time: float
    ):
        """ØªØ­Ù„ÙŠÙ„ ÙˆØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª"""
        log_data = {
            "path": request.path,
            "method": request.method,
            "query_count": query_count,
            "total_time_ms": round(total_time, 2),
        }

        # ØªØ­Ø°ÙŠØ± Ø¹Ù†Ø¯ ØªØ¬Ø§ÙˆØ² Ø¹Ø¯Ø¯ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª
        if query_count >= self.QUERY_COUNT_CRITICAL:
            log_data["level"] = "CRITICAL"
            logger.error(f"CRITICAL_QUERY_COUNT: {log_data}")
        elif query_count >= self.QUERY_COUNT_WARNING:
            log_data["level"] = "WARNING"
            logger.warning(f"HIGH_QUERY_COUNT: {log_data}")

        # ØªØ­Ø°ÙŠØ± Ø¹Ù†Ø¯ Ø¨Ø·Ø¡ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©
        if total_time >= self.TOTAL_TIME_WARNING_MS:
            logger.warning(f"SLOW_RESPONSE: {log_data}")

        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† N+1 queries
        duplicate_queries = self._find_duplicate_queries(queries)
        if duplicate_queries:
            log_data["duplicates"] = duplicate_queries
            logger.warning(f"N+1_DETECTED: {log_data}")

        # ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª Ø§Ù„Ø¨Ø·ÙŠØ¦Ø©
        slow_queries = [
            q
            for q in queries
            if float(q.get("time", 0)) * 1000 > self.QUERY_TIME_WARNING_MS
        ]
        if slow_queries:
            for sq in slow_queries[:5]:  # Ø£ÙˆÙ„ 5 ÙÙ‚Ø·
                logger.warning(
                    f"SLOW_QUERY: {sq['sql'][:200]}... ({float(sq['time'])*1000:.0f}ms)"
                )

    def _find_duplicate_queries(self, queries: list) -> dict:
        """Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª Ø§Ù„Ù…ÙƒØ±Ø±Ø© (N+1 pattern)"""
        # Ù†Ø³ØªØ®Ø¯Ù… pattern matching Ù„Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª Ù…ØªØ´Ø§Ø¨Ù‡Ø©
        query_patterns = {}

        for q in queries:
            sql = q.get("sql", "")
            # ØªØ¨Ø³ÙŠØ· Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø©
            simplified = re.sub(r"\d+", "N", sql)
            simplified = re.sub(r"'[^']*'", "'X'", simplified)

            if simplified not in query_patterns:
                query_patterns[simplified] = 0
            query_patterns[simplified] += 1

        # Ø¥Ø±Ø¬Ø§Ø¹ ÙÙ‚Ø· Ø§Ù„Ù…ÙƒØ±Ø± Ø£ÙƒØ«Ø± Ù…Ù† 3 Ù…Ø±Ø§Øª
        return {k: v for k, v in query_patterns.items() if v > 3}


class CompressionMiddleware:
    """
    Ù…ÙŠØ¯Ù„ÙˆÙŠØ± Ø¶ØºØ· Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø§Øª

    ÙŠØ¶ØºØ· Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø§Øª Ø§Ù„ÙƒØ¨ÙŠØ±Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… gzip
    """

    MIN_SIZE_TO_COMPRESS = 1024  # 1KB
    COMPRESSIBLE_CONTENT_TYPES = [
        "text/html",
        "text/css",
        "text/javascript",
        "application/javascript",
        "application/json",
        "application/xml",
    ]

    def __init__(self, get_response: Callable):
        self.get_response = get_response

    def __call__(self, request: HttpRequest) -> HttpResponse:
        response = self.get_response(request)

        # ÙØ­Øµ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø¹Ù…ÙŠÙ„ ÙŠØ¯Ø¹Ù… gzip
        if "gzip" not in request.META.get("HTTP_ACCEPT_ENCODING", ""):
            return response

        # ÙØ­Øµ Ù†ÙˆØ¹ Ø§Ù„Ù…Ø­ØªÙˆÙ‰
        content_type = response.get("Content-Type", "").split(";")[0]
        if content_type not in self.COMPRESSIBLE_CONTENT_TYPES:
            return response

        # ÙØ­Øµ Ø§Ù„Ø­Ø¬Ù…
        if len(response.content) < self.MIN_SIZE_TO_COMPRESS:
            return response

        # Ø§Ù„Ø¶ØºØ·
        try:
            import gzip

            compressed = gzip.compress(response.content)

            # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø¶ØºÙˆØ· ÙÙ‚Ø· Ø¥Ø°Ø§ ÙƒØ§Ù† Ø£ØµØºØ±
            if len(compressed) < len(response.content):
                response.content = compressed
                response["Content-Encoding"] = "gzip"
                response["Content-Length"] = len(compressed)
        except Exception:
            pass  # ØªØ¬Ø§Ù‡Ù„ Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ø¶ØºØ·

        return response


class SecurityHeadersMiddleware:
    """
    Ù…ÙŠØ¯Ù„ÙˆÙŠØ± Ø¥Ø¶Ø§ÙØ© headers Ø§Ù„Ø£Ù…Ø§Ù†
    """

    def __init__(self, get_response: Callable):
        self.get_response = get_response

    def __call__(self, request: HttpRequest) -> HttpResponse:
        response = self.get_response(request)

        # Ø¥Ø¶Ø§ÙØ© headers Ø§Ù„Ø£Ù…Ø§Ù†
        response["X-Content-Type-Options"] = "nosniff"
        response["X-Frame-Options"] = "SAMEORIGIN"
        response["Referrer-Policy"] = "strict-origin-when-cross-origin"

        return response
